{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import IPython.display as ipd\n",
    "\n",
    "from lava.lib.dl import slayer\n",
    "from audio_dataloader import DNSAudio\n",
    "from snr import si_snr\n",
    "from dnsmos import DNSMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_nas_fullconv_baseline import collate_fn, stft_splitter, stft_mixer, nop_stats, Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wavio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_folder = '../20230707_loh_nas_runs'\n",
    "args = yaml.safe_load(open(trained_folder + '/args.txt', 'rt'))\n",
    "if 'out_delay' not in args.keys():\n",
    "    args['out_delay'] = 0\n",
    "if 'n_fft' not in args.keys():\n",
    "    args['n_fft'] = 512\n",
    "device =  torch.device('cpu') #torch.device('cuda:0')\n",
    "root = '/mnt/data4tb/stadtmann/dns_challenge_4/datasets_fullband/' #args['path']\n",
    "out_delay = args['out_delay']\n",
    "n_fft = args['n_fft']\n",
    "win_length = n_fft\n",
    "hop_length = n_fft // 4\n",
    "stats = slayer.utils.LearningStats(accuracy_str='SI-SNR', accuracy_unit='dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DNSAudio(root=root + 'training_set/')\n",
    "validation_set = DNSAudio(root=root + 'validation_set/')\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=collate_fn,\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True)\n",
    "validation_loader = DataLoader(validation_set,\n",
    "                               batch_size=32,\n",
    "                               shuffle=True,\n",
    "                               collate_fn=collate_fn,\n",
    "                               num_workers=4,\n",
    "                               pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = 5\n",
    "cc = 256\n",
    "dd = 5\n",
    "\n",
    "net = Network(kk,cc,dd,\n",
    "                args['threshold'],\n",
    "                args['tau_grad'],\n",
    "                args['scale_grad'],\n",
    "                args['dmax'],\n",
    "                args['out_delay']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_sample_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy, clean, noise, metadata = train_set[debug_sample_no]\n",
    "noisy = torch.unsqueeze(torch.FloatTensor(noisy), dim=0).to(device)\n",
    "noisy_abs, noisy_arg = stft_splitter(noisy, n_fft)\n",
    "net(noisy_abs)\n",
    "net.load_state_dict(torch.load(trained_folder + '/trained_k5c256d5_optfcn_Adamlr_customschedule' + '/network.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_abs = net(noisy_abs)\n",
    "cleaned = stft_mixer(denoised_abs, noisy_arg, n_fft)\n",
    "\n",
    "wavio.write(\"debug_in.wav\", noisy.squeeze(0).detach(),16000,sampwidth=2)\n",
    "wavio.write(\"debug_out.wav\", cleaned.squeeze(0).detach(),16000,sampwidth=2)\n",
    "wavio.write(\"debug_ref.wav\", clean,16000,sampwidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(noisy.squeeze(0).detach(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(cleaned.squeeze(0).detach(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(clean, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnsmos = DNSMOS()\n",
    "dnsmos_noisy = np.zeros(3)\n",
    "dnsmos_clean = np.zeros(3)\n",
    "dnsmos_noise = np.zeros(3)\n",
    "dnsmos_cleaned  = np.zeros(3)\n",
    "#train_event_counts = []\n",
    "\n",
    "t_st = datetime.now()\n",
    "for i, (noisy, clean, noise) in enumerate(train_loader):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        noisy = noisy.to(device)\n",
    "        clean = clean.to(device)\n",
    "\n",
    "        noisy_abs, noisy_arg = stft_splitter(noisy, n_fft)\n",
    "        clean_abs, clean_arg = stft_splitter(clean, n_fft)\n",
    "\n",
    "        #denoised_abs, count = net(noisy_abs)\n",
    "        denoised_abs = net(noisy_abs)\n",
    "        #train_event_counts.append(count.cpu().data.numpy())\n",
    "        noisy_arg = slayer.axon.delay(noisy_arg, out_delay)\n",
    "        clean_abs = slayer.axon.delay(clean_abs, out_delay)\n",
    "        clean = slayer.axon.delay(clean, win_length * out_delay)\n",
    "\n",
    "        loss = F.mse_loss(denoised_abs, clean_abs)\n",
    "        clean_rec = stft_mixer(denoised_abs, noisy_arg, n_fft)\n",
    "        score = si_snr(clean_rec, clean)\n",
    "\n",
    "        dnsmos_noisy += np.sum(dnsmos(noisy.cpu().data.numpy()), axis=0)\n",
    "        dnsmos_clean += np.sum(dnsmos(clean.cpu().data.numpy()), axis=0)\n",
    "        dnsmos_noise += np.sum(dnsmos(noise.cpu().data.numpy()), axis=0)\n",
    "        dnsmos_cleaned += np.sum(dnsmos(clean_rec.cpu().data.numpy()), axis=0)\n",
    "\n",
    "        stats.training.correct_samples += torch.sum(score).item()\n",
    "        stats.training.loss_sum += loss.item()\n",
    "        stats.training.num_samples += noisy.shape[0]\n",
    "\n",
    "        processed = i * train_loader.batch_size\n",
    "        total = len(train_loader.dataset)\n",
    "        time_elapsed = (datetime.now() - t_st).total_seconds()\n",
    "        samples_sec = time_elapsed / (i + 1) / train_loader.batch_size\n",
    "        header_list = [f'Train: [{processed}/{total} '\n",
    "                        f'({100.0 * processed / total:.0f}%)]']\n",
    "        #header_list.append(f'Event rate: {[c.item() for c in count]}')\n",
    "        print(f'\\r{header_list[0]}', end='')\n",
    "\n",
    "dnsmos_clean /= len(train_loader.dataset)\n",
    "dnsmos_noisy /= len(train_loader.dataset)\n",
    "dnsmos_noise /= len(train_loader.dataset)\n",
    "dnsmos_cleaned /= len(train_loader.dataset)\n",
    "\n",
    "print()\n",
    "stats.print(0, i, samples_sec, header=header_list)\n",
    "print('Avg DNSMOS clean   [ovrl, sig, bak]: ', dnsmos_clean)\n",
    "print('Avg DNSMOS noisy   [ovrl, sig, bak]: ', dnsmos_noisy)\n",
    "print('Avg DNSMOS noise   [ovrl, sig, bak]: ', dnsmos_noise)\n",
    "print('Avg DNSMOS cleaned [ovrl, sig, bak]: ', dnsmos_cleaned)\n",
    "\n",
    "# mean_events = np.mean(train_event_counts, axis=0)\n",
    "\n",
    "# neuronops = []\n",
    "# for block in net.blocks[:-1]:\n",
    "#     neuronops.append(np.prod(block.neuron.shape))\n",
    "\n",
    "# synops = []\n",
    "# for events, block in zip(mean_events, net.blocks[1:]):\n",
    "#     synops.append(events * np.prod(block.synapse.shape))\n",
    "# print(f'SynOPS: {synops}')\n",
    "# print(f'Total SynOPS: {sum(synops)}')\n",
    "# print(f'Total NeuronOPS: {sum(neuronops)}')\n",
    "# print(f'Time-step per sample: {noisy_abs.shape[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnsmos = DNSMOS()\n",
    "dnsmos_noisy = np.zeros(3)\n",
    "dnsmos_clean = np.zeros(3)\n",
    "dnsmos_noise = np.zeros(3)\n",
    "dnsmos_cleaned  = np.zeros(3)\n",
    "#train_event_counts = []\n",
    "\n",
    "t_st = datetime.now()\n",
    "for i, (noisy, clean, noise) in enumerate(validation_loader):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        noisy = noisy.to(device)\n",
    "        clean = clean.to(device)\n",
    "\n",
    "        noisy_abs, noisy_arg = stft_splitter(noisy, n_fft)\n",
    "        clean_abs, clean_arg = stft_splitter(clean, n_fft)\n",
    "\n",
    "        #denoised_abs, count = net(noisy_abs)\n",
    "        denoised_abs = net(noisy_abs)\n",
    "        #train_event_counts.append(count.cpu().data.numpy())\n",
    "        noisy_arg = slayer.axon.delay(noisy_arg, out_delay)\n",
    "        clean_abs = slayer.axon.delay(clean_abs, out_delay)\n",
    "        clean = slayer.axon.delay(clean, win_length * out_delay)\n",
    "\n",
    "        loss = F.mse_loss(denoised_abs, clean_abs)\n",
    "        clean_rec = stft_mixer(denoised_abs, noisy_arg, n_fft)\n",
    "        score = si_snr(clean_rec, clean)\n",
    "\n",
    "        dnsmos_noisy += np.sum(dnsmos(noisy.cpu().data.numpy()), axis=0)\n",
    "        dnsmos_clean += np.sum(dnsmos(clean.cpu().data.numpy()), axis=0)\n",
    "        dnsmos_noise += np.sum(dnsmos(noise.cpu().data.numpy()), axis=0)\n",
    "        dnsmos_cleaned += np.sum(dnsmos(clean_rec.cpu().data.numpy()), axis=0)\n",
    "\n",
    "        stats.training.correct_samples += torch.sum(score).item()\n",
    "        stats.training.loss_sum += loss.item()\n",
    "        stats.training.num_samples += noisy.shape[0]\n",
    "\n",
    "        processed = i * validation_loader.batch_size\n",
    "        total = len(validation_loader.dataset)\n",
    "        time_elapsed = (datetime.now() - t_st).total_seconds()\n",
    "        samples_sec = time_elapsed / (i + 1) / validation_loader.batch_size\n",
    "        header_list = [f'Train: [{processed}/{total} '\n",
    "                        f'({100.0 * processed / total:.0f}%)]']\n",
    "        #header_list.append(f'Event rate: {[c.item() for c in count]}')\n",
    "        print(f'\\r{header_list[0]}', end='')\n",
    "\n",
    "dnsmos_clean /= len(validation_loader.dataset)\n",
    "dnsmos_noisy /= len(validation_loader.dataset)\n",
    "dnsmos_noise /= len(validation_loader.dataset)\n",
    "dnsmos_cleaned /= len(validation_loader.dataset)\n",
    "\n",
    "print()\n",
    "stats.print(0, i, samples_sec, header=header_list)\n",
    "print('Avg DNSMOS clean   [ovrl, sig, bak]: ', dnsmos_clean)\n",
    "print('Avg DNSMOS noisy   [ovrl, sig, bak]: ', dnsmos_noisy)\n",
    "print('Avg DNSMOS noise   [ovrl, sig, bak]: ', dnsmos_noise)\n",
    "print('Avg DNSMOS cleaned [ovrl, sig, bak]: ', dnsmos_cleaned)\n",
    "\n",
    "# mean_events = np.mean(train_event_counts, axis=0)\n",
    "\n",
    "# neuronops = []\n",
    "# for block in net.blocks[:-1]:\n",
    "#     neuronops.append(np.prod(block.neuron.shape))\n",
    "\n",
    "# synops = []\n",
    "# for events, block in zip(mean_events, net.blocks[1:]):\n",
    "#     synops.append(events * np.prod(block.synapse.shape))\n",
    "# print(f'SynOPS: {synops}')\n",
    "# print(f'Total SynOPS: {sum(synops)}')\n",
    "# print(f'Total NeuronOPS: {sum(neuronops)}')\n",
    "# print(f'Time-step per sample: {noisy_abs.shape[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel_dns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
